一. selenium框架使用
    安装：pip install -U selenium
    下载chrome驱动 https://chromedriver.storage.googleapis.com/index.html?path=2.29/
    
    def login_zhihu():  # 模拟登录知乎

    def login_weibo():  # 模拟登录微博

    def scroll_web():  # 模拟鼠标下拉

    def no_image_load():  # 不加载图片
        opt = webdriver.ChromeOptions()
        prefs = {"profile.managed_default_content_settings.images": 2}
        opt.add_experimental_option("prefs", prefs)
        browser = webdriver.Chrome(executable_path='./phantomJS', chrome_options=opt)
        browser.get('http:www.taobao.com')
        browser.quit()


    # phantomjs, 无界面的浏览器， 多进程情况下phantomjs性能会下降很严重
    def phantomJS():
        browser = webdriver.PhantomJS(executable_path="./chromedriver")
        browser.get("https://detail.tmall.com/item.htm?spm=a230r.1.14.3.yYBVG6&id=538286972599&cm_id=140105335569ed55e27b&abbucket=15&sku_properties=10004:709990523;5919063:6536025")

        print(browser.page_source)
        browser.quit()

    if __name__ == '__main__':
        # login_zhihu()
        # login_weibo()
        # scroll_web()
        # no_image_load()
        phantomJS()
    
    
二.  selenium集成到scrapy中去（joboles）：
    def __init__(self):
        self.browser = webdriver.Chrome(executable_path='/python/ArticleSpider/tools/chromedriver')
        super(JobbolesSpider, self).__init__()
        # 当爬虫关闭时发送信号, 处理函数close_chrome执行
        dispatcher.connect(self.close_chrome, signals.spider_closed)  

    def close_chrome(self):
        print('爬虫退出关闭chrome!')
        self.browser.quit()
    中间件处理js界面：
    class JSPageMiddleware(object):  # 需要在settings中配置生效

    def process_request(self, request, spider):  # 处理动态加载的网页
        if spider.name == 'jobboles':
            spider.browser.get(request.url)  # 使用spider创建的chrome动态加载js页面
            time.sleep(1)
            print('访问：{0}'.format(request.url))
            # 对已经交给chrome处理url返回, 不再交给downloader请求下载
            return HtmlResponse(url=spider.browser.current_url,
                                body=spider.browser.page_source, encoding='utf-8', request=request)
                                
                                
三.  无chrome界面处理
pip install pyvirtualdisplay
from pyvirtualdisplay import Display
    display = Display()
    display.start()
    browser = webdriver.Chrome('./chromedriver')
    browser.get('http://www.baidu.com')
    print(browser.page_source)
有可能出现问题, 安装：sudo apt-get install xvfb
四. scrapy-splash
    github搜索
五. selenium grid
    网络搜索
六. splinter
    github搜索
scrapy 暂停与重启
scrapy crawl  lagou -s JOBDIR=job_info/001 （job_info/001保存spider的中间状态信息）
kill -f (-9:强制杀死进程) main.py
scrapy crawl  lagou -s JOBDIR=job_info/001 (再次运行则启动spider, 从之前保存的状态开始运行)
scrapy crawl  lagou -s JOBDIR=job_info/002（重新爬取， 重新开始爬取）

七. spidermiddlware(直接观看它的源码. 进行一些处理，如404等)
httperror
八. 使用信号量扩展功能（extention）






